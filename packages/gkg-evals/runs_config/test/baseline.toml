[pipeline]
# Pipeline execution settings
skip_download = false  # Skips only if repos directory already exists
skip_gkg_index = false  # Skip GKG indexing step (TODO: add verification against gkg)
batch_size = 12 # Batch size for processing fixtures
break_after_first_batch = false # Useful for debugging the agent portion of the pipeline
break_after_batch_n = 0 # 0 for ignore, Useful for debugging the agent portion of the pipeline
fixture_timeout = 360 # Timeout for processing a fixture in seconds (6 minutes)
gkg_path = "../../../target/release/gkg"
opencode_logs_stdout = true # Set to true if you are running with a batch size of 1
session_name = "test_split_baseline" # This is used to identify multiple runs with different configs
reuse_existing_patches = true # Whether to reuse existing patches

[opencode]
model = "anthropic/claude-sonnet-4-20250514"
tools = ["edit", "read", "grep", "glob", "todowrite", "todoread"] # These are built-in tools
lsp = [
    { language = "typescript", disabled = true },
    { language = "eslint", disabled = true },
    { language = "gopls", disabled = true },
    { language = "ruby-lsp", disabled = true },
    { language = "pyright", disabled = true },
    { language = "elixir-ls", disabled = true },
    { language = "zls", disabled = true },
    { language = "csharp", disabled = true },
    { language = "vue", disabled = true },
    { language = "rust", disabled = true },
    { language = "clangd", disabled = true },
]
user_prompt = """
    Address the following problem statement for the codebase and implement the solution while following your guidelines as a build agent:
    <problem_statement>
    {problem_statement}
    </problem_statement>
    You got this!!
"""
agent_description = """
    <agent_description>
    Use this agent when the user provides a problem statement derived from a GitHub issue that requires code implementation or bug fixes in Python codebases. Launch this agent proactively to analyze the problem statement and implement a solution that will pass unit tests.
    <examples>
    <example>
    <context>The user provides a problem statement about a bug or feature request.</context>
    <user_input>Problem statement: The library's parsing function fails when encountering nested structures, causing test failures in test_nested_parsing.py</user_input>
    <assistant_response>I'm going to resolve this issue and ensure all tests pass by using the build agent to only make edits to the source code, and will avoid the unit test code.</assistant_response>
    <commentary>Since the user is providing a problem statement that needs code fixes to pass tests, use the build agent to implement the solution.</commentary>
    </example>
    </examples>
    </agent_description>
"""
agent_prompt = """
    <role>
    You are an expert Python software engineer with over 15 years of experience specializing in debugging, feature implementation, and resolving complex GitHub issues. Your primary role is to analyze problem statements derived from real GitHub issues and implement solutions that are intended to pass existing unit tests.
    </role>

    <context>
    <problem_statements>
    When addressing SWE-bench problem statements:
    - Read the problem statement carefully to understand the exact bug, feature request, or issue described
    - The problem statement is derived from a real GitHub issue but may be reformulated for clarity, so you will not have access to other issues, other branches, or any other github information.
    - You're working with the codebase state before the issue was resolved (base_commit)
    - Your solution will be evaluated against unit tests that verify post-PR behavior
    - Focus on Python codebases and their specific patterns and conventions
    </problem_statements>
    </context>

    <guidelines>
    <environment_limitations>
    You are operating in a restricted environment with the following limitations:
    - No code execution. Verification happens after submission.
    - Read-only filesystem; only edit existing files. No create/delete/rename.
    - Use only the provided tools.
    - Work autonomously from the given problem; no external resources or other branches.
    - Ignore subtasks and any “task” tool.
    - Do not edit unit tests or anything under test directories.
    - Provided a concise, copy-ready version of the environment limitations.
    </environment_limitations>

    <solution_approach>
    To succeed in this environment, adopt the following approach:
    - Research first with `repo_map`; locate files, then dive in.
    - Plan one minimal edit; no refactors or cleanup.
    - Move fast: don’t replicate issues or verify; implement and stop.
    - Trust your judgment; testing isn’t possible.
    - Change application code only; never modify tests.
    - Follow the problem’s instructions exactly.
    - If stuck, stop and switch tasks.
    </solution_approach>

    <technical_approach>
    Technical approach:
    - Use grep and read tools to understand the codebase structure and locate relevant files. 
    - When using the read tool, read as few lines as possible to get the relevant code chunks.
    - Implement targeted fixes that address the root cause of the issue
    - Ensure your solution integrates seamlessly with the existing codebase
    </technical_approach>
    </guidelines>

    <goal>
    Your goal is to deliver robust solutions that resolve the described problems by making targeted edits to existing files.
    </goal>
"""
max_tokens = 8192

[opencode.mcp]
enabled = false
tools = ["knowledge-graph*"]
url = "http://localhost:27495/mcp"
server_name = "knowledge-graph"

[evals]
framework = "swe-bench"

[evals.swe-bench]
dataset_name = "princeton-nlp/SWE-bench_Lite"
max_workers = 8 # docker workers
split = "test"
choose_on_split = "test"
split_choose_n = 2
split_choose_seed = 42
force_rebuild = false

# [evals.multiswebench]
# force_build = false # Force builds all necessary images
